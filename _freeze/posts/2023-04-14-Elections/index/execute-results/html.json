{
  "hash": "0a21cbff3808f91b29bab19f34321937",
  "result": {
    "markdown": "---\ntitle: Regional Voting Preferences in the 2019 Philippine Senatorial Elections\ndescription: 'Looks like voting in the Philippines is all about location, location, location! Literacy and religion may not be factors, but hometown pride definitely is.'\ndate: '2022-04-17'\ncategories:\n  - python\nimage: thumbnail.jpeg\nformat:\n  html:\n    code-fold: true\n---\n\n<!-- <h4>Looks like voting in the Philippines is all about location, location, location! Literacy and religion may not be factors, but hometown pride definitely is.</h4> -->\n![](thumbnail.jpeg)\n\n<h1>Overview</h1>\n\nOriginal submission was last 2019-05-29.\n\nThis jupyter notebook was created for our Data Mining and Wrangling class in AIM MSDS. In particular, this was done during our 2nd semester of class, as one of the core requirements. In this report, we sought to understand the results of the 2019 elections through descriptive statistics. We wanted to do exploratory data analysis on the following questions:\n\n<h1>Acknowledgements</h1>\n\nThis analysis was done together with my Lab partner, Geogre Esleta.\n\n\n<ol>\n<li>  How did the various administrative regions of the Philippines voted for their senators?\n<li>  Is the voter preference homogeneous across the country, or is there a preferred candidate or party per region? More specifically, how does (1) religious affiliation, (2) educational attainment, and (2) sex play a major role on how the voters select their candidates.\n</ol>\n\n<h2>Load Requirement Package</h2>\n\nBefore anything else, let us first load all important modules for this exercise.\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport os\nimport io\nimport re\nimport time\nimport glob\nimport requests\nimport urllib.request\nimport numpy as np\nimport pandas as pd\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import LinearSegmentedColormap\nimport seaborn as sns\n```\n:::\n\n\nIt is important to identify the datasets we are going to use for this exercise. The two identified datasets the group intends to use are: the 2019 National Data and the 2015-2016 Census data.\n\nWith regards to 2019 National data, the team used a web scapper provided Prof. Alis. The web scapper downloaded the election results from the Commission of Elections' 2019 National and Local Elections website. The results were then stored in a local repository which is then easily accesible for the team. The 2019 elections results are broken down into two main directories: results and contest. In this exercise, the team will explore both directories to map out a comprehensive summary of the 2019 senatorial and party elections.\n\nSecondly, the 2015-2016 Census data has already been stored in a local repository for easier access. One of the main reasons why the team decided to use the 2015-2016 Census data is because of the lack of availability of recent data. The Philippine Statistics Authority only releases a comprehensive census survey ever six years. However for the purpose of this exercise, the team has agreed that the 2015-2016 census data can act as an appproximate for today's population.\n\n<h2>Methodology</h2>\n\n<h3>Step 1: Extract and collect the 2019 Elections (Results) data</h3>\n\nThe first directory to explore is the 2019 Election `results`. The `results` directory contains all electoral results from a regional level down to the barangay level. For each level, a specific `coc.json` file is stored. This file contains all electoral results data and metadata for both national and local elections. However for the purposes of this analysis, we will only look at the aggregated elections data at the regional level. The files that we are interested are the coc.json files associated to each province, as these files contain the metadata and data on the election results.\n\nThe main structure of each coc.json file contains the following main keys: `vbc`, `rs`, `sts`, `obs`, and `cos`. For the purpose of this exercise, the important key the group needs to extract is the `rs` key as this provides the each candidate's total votes per area. \nUnder the `rs` key, the following keys can be found: `cc`, `bo`, `v`, `tot`, `per`, and `ser`. Cross referencing these keys with official statements and comelec documentations suggests that important keys are as follows: `cc` pertaining to contest_type, `bo` pertaining to the candidate_id, and `v` pertaining to votes_per_province.\n\n| Paremeter | Description |\n|:-----|------|\n| cc   | Contestant Code |\n| bo  |  Contestant ID |\n| v    | Total Votes Per Contestant |\n| tot    |  Total Votes Per Province |\n\nHowever, it must be pointed out that the available data only goes as high as provincial data. If we want to process the provincial level, the team will have to aggregate the data up.\n\nThe group created utility functions for easier retrieval of the provincial elections datasets. The purpose for the utility functions (and future utility functions) are for initial cleaning and manipulations. This is to ensure each dataset is ready for aggregation.\n\nThe `get_province_coc` method unpacks each key and value from the `coc.json` dictionary into a cleaned up dataframe. In addition, the method identifies which region and province the file originated from by examining the filepath that was passed.\n\nThe `get_all_province_coc` method is a walker that goes through each of the results directory. The walker checks if the filename has an equal value to `coc.json`. If a `coc.json `was located, the `get_province_coc` method is applied with the filepath as the parameter. The resulting dataframe is then appended to a master dataframe for further extraction and analysis. For this exercise, the group only had to extract data up to the regional and provincial levels so only three wildcard were use for the `glob` walker.\n\nSpecial methods (`get_ncr_coc` and `get_all_ncr_coc`) were established to get the cities' `coc.json`. For the case of the NCR cities, theire associated `coc.json` files were one directory lower.\n\n<h4>`get_province_coc` function</h4>\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\ndef get_province_coc(filepath):\n    \"\"\"\n    Loads a single coc file. \n\n    Adds additional columns `region` and `province to the DataFrame,\n    depending on filepath.\n\n    Parameters\n    ----------\n    filepath    : filepath\n\n    Return\n    ------\n    df          : a dataframe\n    \"\"\"\n    output = []\n    with open(filepath, 'r') as f:\n        dirpath, filepath = os.path.split(filepath)\n        region = dirpath.split('/')[-2]\n        province = dirpath.split('/')[-1]\n        data = json.load(f)\n        for each in data['rs']:\n            row = [float(element) for element in list(each.values())]\n            output.append([data['vbc']] + row + [region] + [province])\n    df = pd.DataFrame(output,\n                      columns=['vbc', 'cc', 'bo', 'v', 'tot', 'per', 'ser',\n                               'region', 'province'])\n    return df\n```\n:::\n\n\n<h4>`get_all_province_coc` function</h4>\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\ndef get_all_province_coc(tree):\n    \"\"\"\n    Loads all province COC files and saves them to a dataframe\n\n    Checks the filepath if filename is 'coc.json'\n\n    Created a new column to deal with the reclassification of\n        \"NEGROS ORIENTAL\" and \"NEGROS OCCIDENTAL\" to \"NIR\" \n            to match the PSA 2016 dataset.\n\n    Parameters\n    ----------\n    filepath    : filepath\n\n    Return\n    ------\n    df          : a dataframe\n    \"\"\"\n    total = pd.DataFrame()\n    for file in glob.glob(tree):\n        if os.path.basename(file) == 'coc.json':\n            df = get_province_coc(file)\n            total = total.append(df)\n    total.rename(columns={'region': 'region_raw'}, inplace=True)\n    total['region'] = total['region_raw'].copy()\n    total.loc[(total['province'] == \"NEGROS ORIENTAL\") |\n              (total['province'] == \"NEGROS OCCIDENTAL\"), 'region'] = 'NIR'\n    return total\n```\n:::\n\n\n<h4>`get_ncr_coc` function</h4>\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\ndef get_ncr_coc(filepath):\n    \"\"\"\n    Loads a single coc file. \n\n    Adds additional columns `region` and `province to the DataFrame,\n    depending on filepath.\n\n    Parameters\n    ----------\n    filepath    : filepath\n\n    Return\n    ------\n    df          : a dataframe    \n\n    \"\"\"\n    output = []\n    with open(filepath, 'r') as f:\n        dirpath, filepath = os.path.split(filepath)\n        region = dirpath.split('/')[-3]\n        province = dirpath.split('/')[-2]\n        data = json.load(f)\n        for each in data['rs']:\n            row = [float(element) for element in list(each.values())]\n            output.append([data['vbc']] + row + [region] + [province])\n    df = pd.DataFrame(output,\n                      columns=['vbc', 'cc', 'bo', 'v', 'tot', 'per', 'ser',\n                               'region', 'province'])\n    return df\n```\n:::\n\n\n<h4>`get_all_ncr_coc` function</h4>\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\ndef get_all_ncr_coc(tree):\n    \"\"\"\n    Loads all province COC files and saves them to a dataframe\n\n    Checks the filepath if filename is 'coc.json'\n\n    Parameters\n    ----------\n    filepath    : filepath\n\n    Return\n    ------\n    df          : a dataframe\n    \"\"\"\n    total = pd.DataFrame()\n    for file in glob.glob(tree):\n        if file.split('/')[7] == 'NCR':\n            if os.path.basename(file) == 'coc.json':\n                df = get_ncr_coc(file)\n                total = total.append(df)\n    total.rename(columns={'region': 'region_raw'}, inplace=True)\n    total['region'] = total['region_raw'].copy()\n    return total\n```\n:::\n\n\n#### With these utility functions inplace, the team can now apply these methods for easier access to the 2019 elections data. \n\nWe can now compile all of the election results with the following line:\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\ntree = '/mnt/data/public/elections/nle2019/results/*/*/*'\nncr_tree = '/mnt/data/public/elections/nle2019/results/*/*/*/*'\ndf_results = get_all_province_coc(tree)\ndf_results = df_results.append(get_all_ncr_coc(ncr_tree))\ndf_results.drop_duplicates(inplace=True)\n```\n:::\n\n\nLet's see what we have:\n\n| vbc | cc | bo | v | tot | per | ser | region_raw | province | region |\n|:--|--|---|---|---|---|---|---|---|---|\n| 0 |\t89550 |\t1.0 |\t1.0 |\t2004.0 |\t1708769.0 |\t0.11 |\t2800.0 |\tREGION I |\tILOCOS NORTE |\tREGION I |\n1 |\t89550 |\t1.0 |\t2.0 |\t1607.0 |\t1708769.0 |\t0.09 |\t2800.0 |\tREGION I |\tILOCOS NORTE |\tREGION I |\t\n2 |\t\t89550 |\t\t1.0 |\t\t3.0 |\t\t8772.0 |\t\t1708769.0 |\t0.51 |\t2800.0 |\tREGION I |\tILOCOS NORTE |\tREGION I |\t\n3 |\t\t89550 |\t1.0 |\t4.0 |\t1767.0 |\t1708769.0 |\t0.10 |\t2800.0 |\tREGION I |\tILOCOS NORTE |\tREGION I |\t\n4 |\t\t89550 |\t1.0 |\t5.0 |\t5068.0 |\t1708769.0 |\t0.29 |\t2800.0 |\tREGION I |\tILOCOS NORTE |\tREGION I |\t\n: {tbl-colwidths=\"[5,10,5,5,10,10,5,10,10,30]\"}\n\n### Next, let us examine the obtained dataset with actual election results. \n\nBy cross checking the results with [Comelec data](https://www.comelec.gov.ph/?r=2019NLE/ListsOfCandidates/CertifiedListofCandidates), we can identify the senators and party names.\n\nJust to check our data, we can look at an example senator from the dataset. By choosing `cc=1` and `bo=46`, we are actually highlighting Imee Marcos' senatorial candidacy results.\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\nfig, ax = plt.subplots()\nax.set_xlabel('Votes')\ndf_marcos = df_results.query('cc == 1 & bo == 46').copy()\ndf_marcos.groupby('region').sum()['v'].sort_values(\n    ascending=True).plot.barh(figsize=(10, 10),\n                              title='Contestant: 46 - Imee Marcos',\n                              color='#BF5209', ax=ax);\n```\n:::\n\n\n![](image1.png)\n\nAdditionally, let us check some descriptive statistics for the 2019 Elections dataset. More specifically, let us examine the `v` or `votes` column. The group will be highly dependent on the `votes` data so let us first do some initial statistics and visualizations.\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\ndf_test = df_results.groupby(['region', 'province'])['v'].sum().to_frame()\ndf_test = df_test.rename(columns={'v': 'votes'})\ndf_test.head()\n```\n:::\n\n\n\tvotes\n| region | province | votes |\n|:--|--|--|\n| BARMM\t| BASILAN\t| 2093067.0 |\n| \t| LANAO DEL SUR| 4770462.0 |\n| \t| MAGUINDANAO\t| 5917983.0 |\n| \t| SULU\t| 3529555.0 |\n| \t| TAWI-TAWI\t| 1874486.0 |\n| CAR\t| ABRA\t| 1923481.0 |\n| \t| APAYAO\t| 703002.0 |\n| \t| BENGUET\t| 2426397.0 |\n| \t| IFUGAO\t| 1408688.0 |\n| \t| KALINGA\t| 1621414.0 |\n| \t| MOUNTAIN PROVINCE\t| 1074249.0 |\n| NCR\t| NATIONAL CAPITAL REGION - FOURTH DISTRICT\t| 22896771.0 |\n| \t| NATIONAL CAPITAL REGION - MANILA\t| 13461229.0 |\n| \t| NATIONAL CAPITAL REGION - SECOND DISTRICT\t| 29803007.0 |\n| \t| NATIONAL CAPITAL REGION - THIRD DISTRICT\t| 18481014.0 |\n| \t| TAGUIG - PATEROS\t| 10018306.0 |\n\n\nJust to explore, the code and image below shows the total votes in region 3. Notice that Bulacan has the highest number of votes, followed by Nueva Ecija, then Pampanga.\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\nfig, ax = plt.subplots()\nax.set_xlabel('Votes')\ndf_test.loc['REGION III',\"votes\"].plot.barh(color='#BF5209', ax=ax);\n```\n:::\n\n\n![Votes Distribution in Region III](image2.png){fig-align=\"left\"}\n\nHere we explore the vote distribution in the National Capital Region. The classification of district and cities were broken down by area (Manila, Taguig-Pateros, Second District, Third District, and Fourth District).The top number of votes came from the second district (mainly because of Quezon City), followed by the Fourth District, then the Third District.\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\nfig, ax = plt.subplots()\nax.set_xlabel('Votes')\ndf_test.loc['NCQ',\"votes\"].plot.barh(color='#BF5209', ax=ax);\n```\n:::\n\n\n![Votes Distribution in the National Capital Region](image3.png){fig-align=\"left\"}\n\nNext, we explore the distribution of votes in Region 4-A. Unsurprisingly, the population of votes is high in the population centers of Cavite, then Batangas, then Laguna.\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\nfig, ax = plt.subplots()\nax.set_xlabel('Votes')\ndf_test.loc['REGION IV-A',\"votes\"].plot.barh(color='#BF5209', ax=ax);\n```\n:::\n\n\n![Votes Distribution in the Region IV-A](image4.png){fig-align=\"left\"}\n\nFor now, let us also examine the distribution of election votes in region 7. Unsurprisingly, the votes are concentrated first in Cebu, followed by Bohol and Siquijor.\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\nfig, ax = plt.subplots()\nax.set_xlabel('Votes')\ndf_test.loc['REGION VII',\"votes\"].plot.barh(color='#BF5209', ax=ax);\n```\n:::\n\n\n![Votes Distribution in the Region VII](image5.png){fig-align=\"left\"}\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}